{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffb2de9-bf0e-46ca-b6ae-9acf05c59d7e",
   "metadata": {},
   "source": [
    "# Iris Recognition for Biometrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095f3166-44cd-4917-a3e0-576ef9c8cd2e",
   "metadata": {},
   "source": [
    "## Background:\n",
    "Normal human vision consists of a series of rapid eye movements called saccades, which exhibit ballistic and abrupt motion behavior. By tracking optokinetic motion with displayed stimulus patterns on a screen, a person's visual performance can be measured from their gaze. Eye trackers are used in visual system research, psychology, psycholinguistics, marketing, and even to detect drowsiness in drivers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9179cae4-1af6-4065-8b55-5c9acbd5bc26",
   "metadata": {},
   "source": [
    "## The problem:\n",
    "Capturing and processing biodata in the real world is noisy and tedious. Describe a DL /AI architecture, algorithm, framework, bioinformatics approach, protocol, method, or approach you would take to process and extract human gaze from a camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62851b27-68b7-4065-9d00-f7fd84956ef0",
   "metadata": {},
   "source": [
    "## Proposed Solution: \n",
    "For this problem, I will be using the Daugman Algorithm so that I will be able to detect the iris of an eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a128cb34-7f3d-4ba0-9985-7a306e4dd9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import itertools\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "bdd893f4-0fe4-45d1-b7df-181acf897ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daugman(grey_image, center, min_radius, max_radius, step):\n",
    "    \n",
    "    intensities = []\n",
    "    list_of_radiuses = list(range(min_radius, max_radius, step)) # list of radius rings we want to analyse\n",
    "    mask = np.zeros_like(grey_image)\n",
    "    for radius in list_of_radiuses:\n",
    "        # drawing a circle on the mask\n",
    "        cv2.circle(mask, center, radius, 255, 1)\n",
    "        \n",
    "        # extracting out the ring\n",
    "        contrast = grey_image & mask\n",
    "        \n",
    "        total_intensity = np.sum(contrast.flatten())\n",
    "        average_intensity = total_intensity / (2 * math.pi * radius) # finding the average intensity\n",
    "        intensities.append(average_intensity)\n",
    "\n",
    "        mask = np.zeros_like(grey_image) # restart mask\n",
    "    \n",
    "    \n",
    "    intensities = np.array(intensities)\n",
    "    \n",
    "    # finding the difference between each intensity ring\n",
    "    intensities_diff = np.diff(intensities)\n",
    "    \n",
    "    intensities_diff = abs(cv2.GaussianBlur(intensities_diff, (1, 5), 0))\n",
    "\n",
    "\n",
    "    index = np.argmax(intensities_diff) # finding the index of the maximum difference in intensity\n",
    "    \n",
    "    return intensities_diff[index], list_of_radiuses[index]\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ae405bd6-f92a-4d30-9d85-1f110d5259f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris(grey_image, min_radius, max_radius, step_coords, step_radius):\n",
    "    \n",
    "    height, width = grey_image.shape\n",
    "    if height != width:\n",
    "        # crop image into a square\n",
    "        if height < width:\n",
    "            grey_image = grey_image[:, int((width-height)/2): width-int((width-height)/2)-1]\n",
    "        else:\n",
    "            grey_image = grey_image[int((height-width)/2): height-int((height-width)/2)-1,:]\n",
    "        \n",
    "    height, width = grey_image.shape\n",
    "        \n",
    "    # let us assume that the iris is in the centre 1/3 of the image\n",
    "    \n",
    "    # list of coordinates that are inside the centre 1/3 of the image...\n",
    "    one_third_x = list(range(int(height/3), int(height/3 * 2), step_coords))\n",
    "    centre_third_square = itertools.product(one_third_x, one_third_x) # collecting coordinates in the centre 1/3\n",
    "    intensity = []\n",
    "    coords = []\n",
    "    \n",
    "    for pt in centre_third_square:\n",
    "        intenseness, radius = daugman(grey_image, pt, min_radius, max_radius, step_radius)\n",
    "        intensity.append(intenseness)\n",
    "        coords.append((pt, radius))\n",
    "        \n",
    "    \n",
    "    intensity = np.array(intensity)\n",
    "    max_index = np.argmax(intensity)\n",
    "\n",
    "    return coords[max_index]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0535074f-8bbe-43c0-8598-85c328923c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58, 57), 36)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('eye2.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "iris(image, 15, 100, 1, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff79e2-70fd-45a6-982b-afc84f2866bb",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "The algorithm used to find the centre coordinates and the radius of the iris and pupil is Daugman. The operator searches for the circular path where there is maximum change in pixel values, varying the raiuds and the centre of the contour. Ths is applied iteratively, only for the centre 1/3 of the image as we assume the pupil is in the centre of the image.\n",
    "\n",
    "A Gaussian filter is applied to smooth the images of the eye in order to remove noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7785da1d-8166-4bbe-a1cf-36dd55a1458f",
   "metadata": {},
   "source": [
    "## Further Improvements\n",
    "\n",
    "This is still a relatively basic implementation of the Daugman algorithm. In pictures of eyes, there can sometimes be [a light reflection that is circular in nature](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.advancedeyecarecenter.net%2F2019%2F12%2F25%2Fdry-eyes-light-sensitivity%2F&psig=AOvVaw3PQhlDHwn17v5iHOne-jrT&ust=1675872524565000&source=images&cd=vfe&ved=0CA8QjRxqFwoTCOjwveXlg_0CFQAAAAAdAAAAABAE). This light spots increase the intensity of the image and results in noisiness.\n",
    "\n",
    "To counter this, we can use an operator to fill in the light-affected regions with the average intensities of pixels from the region surrounding it. The image can be modified using MATLAB imfill before being processed. \n",
    "\n",
    "Additionally, the iris border is expected to lie completely inside the image. For every point that we iterate through, the sum of values inside the radius ring is noted. Hence, those which has rings that lie outside of the image dimension can be neglected. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
